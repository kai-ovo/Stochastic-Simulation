{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Variates for Monte Carlo Variance Reduction\n",
    "## Kai Chang\n",
    "\n",
    "In this write-up, following the `mc.ipynb`, we consider applying several advanced variance-reducing techniques for Monte Carlo simulations. We apply these schemes in the context of simulating a stochastic differential equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solve 1-D diffusion equation with given diffusivity field k\n",
    "and left-hand flux F.\n",
    "\n",
    "ARGUMENTS: \n",
    "    xgrid = vector with equidistant grid points\n",
    "        F = flux at left-hand boundary, k*du/dx = -F \n",
    "   source = source term, either a vector of values at points in xgrid\n",
    "            or a constant\n",
    "  rightbc = Dirichlet BC on right-hand boundary\n",
    "Domain is given by xgrid (should be [0,1])\n",
    "\"\"\"\n",
    "def diffusioneqn(xgrid, F, k, source, rightbc):\n",
    "    N = len(xgrid)\n",
    "    h = xgrid[N-1] - xgrid[N-2]\n",
    "    \n",
    "    A = np.zeros((N-1, N-1))\n",
    "    b = np.zeros(N-1)\n",
    "    \n",
    "    if isinstance(source, (int, float)):\n",
    "        f = -source * np.ones(N-1)\n",
    "    else:\n",
    "        f = -source[:N-1]\n",
    "    \n",
    "    A -= np.diag(2*k[:-1] + k[1:] + np.insert(k[:-2],0,k[0]))\n",
    "    A += np.diag(  k[:-2] + k[1:-1], 1)\n",
    "    A += np.diag(  k[:-2] + k[1:-1],-1)\n",
    "    A /= 2 * h**2\n",
    "    \n",
    "    A[0, 1] += k[0] / h**2\n",
    "    b[0] = 2 * F / h\n",
    "    \n",
    "    b[N-2] = rightbc * (k[N-1] + k[N-2]) / (2 * h**2)\n",
    "    \n",
    "    uinternal = np.linalg.solve(A, f - b)\n",
    "    usolution = np.append(uinternal, rightbc)\n",
    "    \n",
    "    return usolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first try to estimate the mean of the solution. To do so, we draw $n$ i.i.d. realizations of $(Y_1,Y_2,Y_3,Y_4,F)$, solve for $u(0.6,w)$ and take a sample average $\\bar{U}_n = \\dfrac{1}{n}\\sum_{i=1}^n u(0.6,w_i)$. The 95% confidence interval then reads\n",
    "$$\n",
    "[\\bar{U}_n - 1.96\\frac{\\hat{\\sigma}_n}{\\sqrt{n}}, \\bar{U}_n + 1.96\\frac{\\hat{\\sigma}_n}{\\sqrt{n}}]\n",
    "$$\n",
    "where $\\hat{\\sigma}_n$ is the $n$-sample estimate of the standard deviation, which reads\n",
    "$$\n",
    "\\hat{\\sigma}_n = \\sqrt{\\dfrac{1}{n-1}\\sum_{i=1}^n \\left(u(0.6,w_i) - \\bar{U}_n\\right)^2}.\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgrid = np.linspace(0,1,101)\n",
    "sx = 5 \n",
    "rbc = 1\n",
    "\n",
    "def draw_diff(n):\n",
    "    \"\"\" \n",
    "    return : \n",
    "        K : (n,4) - n independent diffusivity function on the grid\n",
    "        Y : (n,4) - normal samples that define K\n",
    "    \"\"\"\n",
    "    X = np.repeat(xgrid.reshape(1,-1), n, axis=0)\n",
    "    K = np.zeros_like(X)\n",
    "    Y = normal(-1, 1, size=(n,4))\n",
    "    K[:,:25] = np.exp(Y[:,0:1].repeat(25,axis=1))\n",
    "    K[:,25:50] = np.exp(Y[:,1:2].repeat(25,axis=1))\n",
    "    K[:,50:75] = np.exp(Y[:,2:3].repeat(25,axis=1))\n",
    "    K[:,75:] = np.exp(Y[:,3:].repeat(26,axis=1))\n",
    "    return K\n",
    "\n",
    "def draw_flux(n):\n",
    "    return normal(-2, np.sqrt(.5), size=n)\n",
    "\n",
    "def sde_mc(n, X=None):\n",
    "    \"\"\" \n",
    "    MC simulation of sde at x = 0.6\n",
    "\n",
    "    input:\n",
    "        X : (n,5) - custom (Y,F) samples\n",
    "            if None, just use the normal samples\n",
    "\n",
    "    output: \n",
    "        u06 : (n,) simulation result\n",
    "        S : (n,5) (Y,F) samples\n",
    "    \"\"\"\n",
    "    u06 = []\n",
    "    if X is None:\n",
    "        K = draw_diff(n)\n",
    "        F = draw_flux(n)\n",
    "    else: \n",
    "        assert X.shape == (n,5)\n",
    "        K = np.zeros((n,101))\n",
    "        Y = X[:,:-1]\n",
    "        F = X[:,-1]\n",
    "\n",
    "        # define diffusivity from Y\n",
    "        K[:,:25] = np.exp(Y[:,0:1].repeat(25,axis=1))\n",
    "        K[:,25:50] = np.exp(Y[:,1:2].repeat(25,axis=1))\n",
    "        K[:,50:75] = np.exp(Y[:,2:3].repeat(25,axis=1))\n",
    "        K[:,75:] = np.exp(Y[:,3:].repeat(26,axis=1))\n",
    "\n",
    "\n",
    "    for i in range(n):\n",
    "        k = K[i,:]\n",
    "        f = F[i]\n",
    "        u = diffusioneqn(xgrid, f, k, sx, rbc)\n",
    "        u06.append(u[60])\n",
    "\n",
    "    return u06\n",
    "\n",
    "def sde_mean(n, X=None):\n",
    "    \"\"\" \n",
    "    MC estimate of sde mean at x = 0.6\n",
    "    res : (3,)\n",
    "        res[0] : left end of 95% CI\n",
    "        res[1] : sample mean estimate\n",
    "        res[2] : right end of 95% CI\n",
    "        res[3] : standard error\n",
    "    \"\"\"\n",
    "    res = np.zeros((4,))\n",
    "    u06 = sde_mc(n, X=X)\n",
    "    mu = np.mean(u06)\n",
    "    res[1] = mu\n",
    "    std = np.std(u06)\n",
    "    res[0] = mu - 1.96*std/np.sqrt(n) # CI left\n",
    "    res[2] = mu + 1.96*std/np.sqrt(n) # CI right\n",
    "    res[3] = std/np.sqrt(n) # SE\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the mean estimate for $n$ ranging from 1000 to 10000, with a step size of 1000. The left and right ends of the 95% confidence interval (CI) are presented separately. The estimated standard error is also presented for reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>CI Left</th>\n",
       "      <th>Sample Mean</th>\n",
       "      <th>CI Right</th>\n",
       "      <th>SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>4.235773</td>\n",
       "      <td>4.536295</td>\n",
       "      <td>4.836818</td>\n",
       "      <td>0.153328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>4.234899</td>\n",
       "      <td>4.393714</td>\n",
       "      <td>4.552529</td>\n",
       "      <td>0.081028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>4.453821</td>\n",
       "      <td>4.597620</td>\n",
       "      <td>4.741418</td>\n",
       "      <td>0.073367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000</td>\n",
       "      <td>4.364170</td>\n",
       "      <td>4.497932</td>\n",
       "      <td>4.631694</td>\n",
       "      <td>0.068246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "      <td>4.462437</td>\n",
       "      <td>4.574848</td>\n",
       "      <td>4.687259</td>\n",
       "      <td>0.057353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6000</td>\n",
       "      <td>4.500294</td>\n",
       "      <td>4.602541</td>\n",
       "      <td>4.704788</td>\n",
       "      <td>0.052167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7000</td>\n",
       "      <td>4.454526</td>\n",
       "      <td>4.545566</td>\n",
       "      <td>4.636605</td>\n",
       "      <td>0.046449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8000</td>\n",
       "      <td>4.543677</td>\n",
       "      <td>4.634582</td>\n",
       "      <td>4.725488</td>\n",
       "      <td>0.046380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9000</td>\n",
       "      <td>4.417137</td>\n",
       "      <td>4.495868</td>\n",
       "      <td>4.574598</td>\n",
       "      <td>0.040169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>4.479502</td>\n",
       "      <td>4.557361</td>\n",
       "      <td>4.635221</td>\n",
       "      <td>0.039724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n   CI Left  Sample Mean  CI Right        SE\n",
       "0   1000  4.235773     4.536295  4.836818  0.153328\n",
       "1   2000  4.234899     4.393714  4.552529  0.081028\n",
       "2   3000  4.453821     4.597620  4.741418  0.073367\n",
       "3   4000  4.364170     4.497932  4.631694  0.068246\n",
       "4   5000  4.462437     4.574848  4.687259  0.057353\n",
       "5   6000  4.500294     4.602541  4.704788  0.052167\n",
       "6   7000  4.454526     4.545566  4.636605  0.046449\n",
       "7   8000  4.543677     4.634582  4.725488  0.046380\n",
       "8   9000  4.417137     4.495868  4.574598  0.040169\n",
       "9  10000  4.479502     4.557361  4.635221  0.039724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "nn = np.arange(1000,10001,1000)\n",
    "resmat = np.zeros((4,len(nn)))\n",
    "for count, n in enumerate(nn):\n",
    "    resmat[:, count] = sde_mean(n)\n",
    "\n",
    "d = {'n' : nn,\n",
    "     'CI Left' : resmat[0,:], \n",
    "     'Sample Mean' : resmat[1,:],\n",
    "     'CI Right' : resmat[2,:], \n",
    "     'SE' : resmat[3,:]}\n",
    "df_mean = pd.DataFrame(d)\n",
    "display(df_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.(b)\n",
    "\n",
    "We use the usual unbiased variance estimator, denoted as $\\hat{\\sigma}_n^2$. The standard error (SE) is $\\frac{2\\hat{\\sigma}_n^4}{n-1}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sde_var(n, X=None):\n",
    "    \"\"\" \n",
    "    MC estimate of sde variance at x = 0.6\n",
    "\n",
    "    res : (2,)\n",
    "        res[0] : estimated variacne\n",
    "        res[1] : estimated standard error - 2\\sigma^4 / (n-1)\n",
    "    \"\"\"\n",
    "    res = np.zeros((2,))\n",
    "    u06 = sde_mc(n, X=X)\n",
    "    var = np.var(u06)\n",
    "    res[0] = var\n",
    "    res[1] = 2*var**2 / (n-1)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the variance estimate for $n$ ranging from 1000 to 10000, with a step size of 1000. The estimated variance is presented along with the estimated standard error (SE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>Variance</th>\n",
       "      <th>SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>12.276527</td>\n",
       "      <td>0.301728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>25.986476</td>\n",
       "      <td>0.675635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>14.233075</td>\n",
       "      <td>0.135099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000</td>\n",
       "      <td>14.986581</td>\n",
       "      <td>0.112327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "      <td>15.020409</td>\n",
       "      <td>0.090263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6000</td>\n",
       "      <td>18.812687</td>\n",
       "      <td>0.117992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7000</td>\n",
       "      <td>16.365337</td>\n",
       "      <td>0.076532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8000</td>\n",
       "      <td>16.386115</td>\n",
       "      <td>0.067135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9000</td>\n",
       "      <td>16.103674</td>\n",
       "      <td>0.057635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>18.441665</td>\n",
       "      <td>0.068026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n   Variance        SE\n",
       "0   1000  12.276527  0.301728\n",
       "1   2000  25.986476  0.675635\n",
       "2   3000  14.233075  0.135099\n",
       "3   4000  14.986581  0.112327\n",
       "4   5000  15.020409  0.090263\n",
       "5   6000  18.812687  0.117992\n",
       "6   7000  16.365337  0.076532\n",
       "7   8000  16.386115  0.067135\n",
       "8   9000  16.103674  0.057635\n",
       "9  10000  18.441665  0.068026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn = np.arange(1000,10001,1000)\n",
    "resmat = np.zeros((2,len(nn)))\n",
    "for count, n in enumerate(nn):\n",
    "    resmat[:,count] = sde_var(n)\n",
    "\n",
    "d = {'n' : nn,\n",
    "     'Variance' : resmat[0,:], \n",
    "     'SE' : resmat[1,:]}\n",
    "df_var = pd.DataFrame(d)\n",
    "display(df_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.(c) Control Variate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X = u(0.6,w)$ and $Y=(Y_1,Y_2,Y_3,Y_4,F)$. Define the control variate (CV) $Z = a^TY$ to be a linearization of $Y$. Let \n",
    "$$X^{cv}=X + c(Z-\\mu_Z).$$\n",
    "Then $\\mathbb{E}[X^{cv}] = \\mathbb{E}[X].$ As shown in class, the optimal $c$ has the form of \n",
    "$$\n",
    "c^* = -\\dfrac{\\text{Cov}(X,Z)}{\\text{Var}(Z)}.\n",
    "$$ \n",
    "To estimate the variance of the CV estimator, we sample 50 independent $n$-sample sequences, compute 100 CV estimates, and estimate the variance from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "def draw_Y(n):\n",
    "    \"\"\" \n",
    "    return : (n,5) sample\n",
    "    \"\"\"\n",
    "    mu = np.asarray([-1,-1,-1,-1,-2])\n",
    "    s = np.asarray([1,1,1,1,0.5])\n",
    "    S = np.diag(s)\n",
    "    var = mvn(mean=mu, cov=S)\n",
    "    return var.rvs(size=n)\n",
    "\n",
    "def XYZ(n,a):\n",
    "    a = a.reshape(-1,1)\n",
    "    Y = draw_Y(n)\n",
    "    Z = (Y@a).squeeze()\n",
    "    X = sde_mc(n,X=Y)\n",
    "    return X,Y,Z\n",
    "\n",
    "def est_coeff(n,a):\n",
    "    X,Y,Z = XYZ(n,a)\n",
    "    X = np.asarray(X)\n",
    "    XZ = X * Z \n",
    "\n",
    "    # cov(X,Z)\n",
    "    mu = np.asarray([-1,-1,-1,-1,-2])\n",
    "    mu_Z = np.dot(a,mu)\n",
    "    cov_XZ = XZ.mean() - X.mean() * mu_Z\n",
    "\n",
    "    # var(Z)\n",
    "    s = np.asarray([1,1,1,1,0.5])\n",
    "    var_Z = (s*np.power(a,2)).sum() # a'Sa \n",
    "\n",
    "    return -cov_XZ / var_Z     \n",
    "\n",
    "def ctrl_var(n, a, c):\n",
    "    \"\"\" \n",
    "    n : #samples for estimating mean\n",
    "    nc : #samples for estimating c\n",
    "    \"\"\"\n",
    "    X,Y,Z = XYZ(n,a)\n",
    "    mu_vec = np.asarray([-1,-1,-1,-1,-2])\n",
    "    mu_Z = np.dot(a,mu_vec)\n",
    "    Xcv = X + c*(Z-mu_Z)\n",
    "    res = np.zeros(4)\n",
    "\n",
    "    mu = Xcv.mean()\n",
    "    res[1] = mu\n",
    "    std = np.std(Xcv)\n",
    "    res[0] = mu - 1.96*std/np.sqrt(n) # CI left\n",
    "    res[2] = mu + 1.96*std/np.sqrt(n) # CI right\n",
    "    res[3] = std/np.sqrt(n) # SE\n",
    "    return res\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the experiment result for CV below. We choose $a = [0,0,0,-1,3]$. Note that this is purely based on heuristics. We compute the standard error (SE) and the 95% confidence interval. We keep $n$ the same as the previous experiments and compare the SE with the one for the vanilla Monte Carlo estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>CI Left</th>\n",
       "      <th>CV Mean</th>\n",
       "      <th>CI Right</th>\n",
       "      <th>CV SE</th>\n",
       "      <th>Vanilla SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>4.279330</td>\n",
       "      <td>4.532297</td>\n",
       "      <td>4.785264</td>\n",
       "      <td>0.129065</td>\n",
       "      <td>0.153328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>4.386884</td>\n",
       "      <td>4.534239</td>\n",
       "      <td>4.681595</td>\n",
       "      <td>0.075181</td>\n",
       "      <td>0.081028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>4.409243</td>\n",
       "      <td>4.529777</td>\n",
       "      <td>4.650311</td>\n",
       "      <td>0.061497</td>\n",
       "      <td>0.073367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000</td>\n",
       "      <td>4.387149</td>\n",
       "      <td>4.489224</td>\n",
       "      <td>4.591299</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>0.068246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "      <td>4.452020</td>\n",
       "      <td>4.552178</td>\n",
       "      <td>4.652337</td>\n",
       "      <td>0.051101</td>\n",
       "      <td>0.057353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6000</td>\n",
       "      <td>4.366468</td>\n",
       "      <td>4.445503</td>\n",
       "      <td>4.524537</td>\n",
       "      <td>0.040324</td>\n",
       "      <td>0.052167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7000</td>\n",
       "      <td>4.482305</td>\n",
       "      <td>4.562971</td>\n",
       "      <td>4.643636</td>\n",
       "      <td>0.041156</td>\n",
       "      <td>0.046449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8000</td>\n",
       "      <td>4.509084</td>\n",
       "      <td>4.580774</td>\n",
       "      <td>4.652464</td>\n",
       "      <td>0.036576</td>\n",
       "      <td>0.046380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9000</td>\n",
       "      <td>4.501744</td>\n",
       "      <td>4.572228</td>\n",
       "      <td>4.642712</td>\n",
       "      <td>0.035961</td>\n",
       "      <td>0.040169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>4.481907</td>\n",
       "      <td>4.545480</td>\n",
       "      <td>4.609052</td>\n",
       "      <td>0.032435</td>\n",
       "      <td>0.039724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n   CI Left   CV Mean  CI Right     CV SE  Vanilla SE\n",
       "0   1000  4.279330  4.532297  4.785264  0.129065    0.153328\n",
       "1   2000  4.386884  4.534239  4.681595  0.075181    0.081028\n",
       "2   3000  4.409243  4.529777  4.650311  0.061497    0.073367\n",
       "3   4000  4.387149  4.489224  4.591299  0.052079    0.068246\n",
       "4   5000  4.452020  4.552178  4.652337  0.051101    0.057353\n",
       "5   6000  4.366468  4.445503  4.524537  0.040324    0.052167\n",
       "6   7000  4.482305  4.562971  4.643636  0.041156    0.046449\n",
       "7   8000  4.509084  4.580774  4.652464  0.036576    0.046380\n",
       "8   9000  4.501744  4.572228  4.642712  0.035961    0.040169\n",
       "9  10000  4.481907  4.545480  4.609052  0.032435    0.039724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define linearization\n",
    "np.random.seed(0)\n",
    "a = [0.,0.,0.,-1.,3.]\n",
    "a = np.asarray(a)\n",
    "\n",
    "# estimate c\n",
    "nc = 10000\n",
    "c = est_coeff(nc,a)\n",
    "\n",
    "nn = np.arange(1000,10001,1000)\n",
    "# nn = [3000]\n",
    "resmat = np.zeros((4,len(nn)))\n",
    "for count, n in enumerate(nn):\n",
    "    resmat[:,count] = ctrl_var(n,a,c)\n",
    "\n",
    "d = {'n' : nn,\n",
    "     'CI Left' : resmat[0,:], \n",
    "     'CV Mean' : resmat[1,:],\n",
    "     'CI Right' : resmat[2,:], \n",
    "     'CV SE' : resmat[3,:],\n",
    "     'Vanilla SE' : df_mean.get('SE')}\n",
    "df_cv = pd.DataFrame(d)\n",
    "display(df_cv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result, we see that with this particular CV, we get at least 10% of variance reduction for those $n$ we have tested on compared to the vanilla Monte Carlo. In many cases, we get 20% of reduction. Note that our CV is chosen based on the trial-and-error heuristic with just a couple of experiments. With a more systematic and careful way of designing the CV, there must be a lot more space to improve the method. This demonstrates the superior performance and potential of CV. \n",
    "\n",
    "Below we consider two cases where $\\mu_Z$ is very big or small. We first consider the big one by making the norm of $\\mu_Z$ 10000 times bigger. We compare the SE of this amplified CV with the previous normal CV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>Big CV</th>\n",
       "      <th>Normal CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.129065</td>\n",
       "      <td>0.129065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.075181</td>\n",
       "      <td>0.075181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.061497</td>\n",
       "      <td>0.061497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>0.052079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.051101</td>\n",
       "      <td>0.051101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6000</td>\n",
       "      <td>0.040324</td>\n",
       "      <td>0.040324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7000</td>\n",
       "      <td>0.041156</td>\n",
       "      <td>0.041156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.036576</td>\n",
       "      <td>0.036576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9000</td>\n",
       "      <td>0.035961</td>\n",
       "      <td>0.035961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.032435</td>\n",
       "      <td>0.032435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n    Big CV  Normal CV\n",
       "0   1000  0.129065   0.129065\n",
       "1   2000  0.075181   0.075181\n",
       "2   3000  0.061497   0.061497\n",
       "3   4000  0.052079   0.052079\n",
       "4   5000  0.051101   0.051101\n",
       "5   6000  0.040324   0.040324\n",
       "6   7000  0.041156   0.041156\n",
       "7   8000  0.036576   0.036576\n",
       "8   9000  0.035961   0.035961\n",
       "9  10000  0.032435   0.032435"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define linearization\n",
    "np.random.seed(0)\n",
    "a = [0.,0.,0.,-1.,3.]\n",
    "a = np.asarray(a) * 10000\n",
    "\n",
    "# estimate c\n",
    "nc = 10000\n",
    "c = est_coeff(nc,a)\n",
    "\n",
    "nn = np.arange(1000,10001,1000)\n",
    "# nn = [3000]\n",
    "resmat = np.zeros((4,len(nn)))\n",
    "for count, n in enumerate(nn):\n",
    "    resmat[:,count] = ctrl_var(n,a,c)\n",
    "\n",
    "d = {'n' : nn,\n",
    "     'Big CV' : resmat[3,:],\n",
    "     'Normal CV' : df_cv.get('CV SE')}\n",
    "df_cv_big = pd.DataFrame(d)\n",
    "display(df_cv_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we consider the small one by making $\\mu_Z$ 10000 times smaller and compare with the previous two different CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>Big CV</th>\n",
       "      <th>Normal CV</th>\n",
       "      <th>Small CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.129065</td>\n",
       "      <td>0.129065</td>\n",
       "      <td>0.129065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.075181</td>\n",
       "      <td>0.075181</td>\n",
       "      <td>0.075181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.061497</td>\n",
       "      <td>0.061497</td>\n",
       "      <td>0.061497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>0.052079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.051101</td>\n",
       "      <td>0.051101</td>\n",
       "      <td>0.051101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6000</td>\n",
       "      <td>0.040324</td>\n",
       "      <td>0.040324</td>\n",
       "      <td>0.040324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7000</td>\n",
       "      <td>0.041156</td>\n",
       "      <td>0.041156</td>\n",
       "      <td>0.041156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.036576</td>\n",
       "      <td>0.036576</td>\n",
       "      <td>0.036576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9000</td>\n",
       "      <td>0.035961</td>\n",
       "      <td>0.035961</td>\n",
       "      <td>0.035961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.032435</td>\n",
       "      <td>0.032435</td>\n",
       "      <td>0.032435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n    Big CV  Normal CV  Small CV\n",
       "0   1000  0.129065   0.129065  0.129065\n",
       "1   2000  0.075181   0.075181  0.075181\n",
       "2   3000  0.061497   0.061497  0.061497\n",
       "3   4000  0.052079   0.052079  0.052079\n",
       "4   5000  0.051101   0.051101  0.051101\n",
       "5   6000  0.040324   0.040324  0.040324\n",
       "6   7000  0.041156   0.041156  0.041156\n",
       "7   8000  0.036576   0.036576  0.036576\n",
       "8   9000  0.035961   0.035961  0.035961\n",
       "9  10000  0.032435   0.032435  0.032435"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define linearization\n",
    "np.random.seed(0)\n",
    "a = [0.,0.,0.,-1.,3.]\n",
    "a = np.asarray(a) / 10000\n",
    "\n",
    "# estimate c\n",
    "nc = 10000\n",
    "c = est_coeff(nc,a)\n",
    "\n",
    "nn = np.arange(1000,10001,1000)\n",
    "resmat = np.zeros((4,len(nn)))\n",
    "for count, n in enumerate(nn):\n",
    "    resmat[:,count] = ctrl_var(n,a,c)\n",
    "\n",
    "d = {'n' : nn,\n",
    "     'Big CV' : df_cv_big.get('Big CV'),\n",
    "     'Normal CV' : df_cv.get('CV SE'),\n",
    "     'Small CV' : resmat[3,:]}\n",
    "df_cv_small = pd.DataFrame(d)\n",
    "display(df_cv_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the variance stays exactly the same for these three cases. This is because the mean is subtracted from $Z$ in the CV estimator anyway, so as long as $a$ stays in the same direction, since this is a simple linear CV construction, the performance will be exactly the same with the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Rare Event Simulation\n",
    "\n",
    "Define random variable $X := \\mathbb{1}\\{u(0.6,w) > 40\\}$. Note that\n",
    "$$\n",
    "\\mathbb{E}\\left[X\\right] = \\mathbb{P}\\left[u(0.6,w) > u_0\\right] = p\n",
    "$$\n",
    "where $\\mathbb{1}\\{\\cdot\\}$ is the indicator. Since $X$ is Bernoulli, we also have\n",
    "$$\n",
    "\\text{Var}(X) = p(1-p).\n",
    "$$\n",
    "The Monte Carlo estimate of the mean and the standard deviation the estimate thereby reads\n",
    "$$\n",
    "\\hat{p}_n = \\dfrac{1}{n} \\sum_{i=1}^n \\mathbb{1}\\{u(0.6,w_i) > 40\\}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\hat{\\sigma}_n = \\sqrt{\\dfrac{\\hat{p}_n(1-\\hat{p}_n)}{n}}.\n",
    "$$\n",
    "We report the estimated relative error per sample (noted as REPS) $\\dfrac{\\sqrt{n}\\hat{\\sigma}_n}{\\hat{p}_n} = \\sqrt{\\dfrac{1-\\hat{p}_n}{\\hat{p}_n}}$ accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_mc(n, X=None, IS=False, wx=None):\n",
    "    \"\"\" \n",
    "    MC estimate of the indicator's mean and variance\n",
    "\n",
    "    \"\"\"\n",
    "    if IS: \n",
    "        assert wx is not None\n",
    "        assert X is not None \n",
    "        \n",
    "    res = np.zeros((3,))\n",
    "    u06 = sde_mc(n, X=X)\n",
    "    u06 = np.asarray(u06)\n",
    "    hx = np.where(u06 > 40, 1, 0)\n",
    "    \n",
    "    if IS:\n",
    "        p = np.mean(wx * hx)\n",
    "        wx2 = np.power(wx,2).sum()\n",
    "        std = np.sqrt(p * (1-p) * wx2) / n\n",
    "        reps = std * np.sqrt(n) / p\n",
    "    else:\n",
    "        p = np.mean(hx)\n",
    "        std = np.sqrt(p*(1-p)/n)\n",
    "        reps = np.sqrt((1-p)/p)\n",
    "    \n",
    "    res[0] = p # mean estimate\n",
    "    res[1] = std # std estimate\n",
    "    res[2] = reps # relative error per sample\n",
    "\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We increase our number of samples to accomodate for the rareness. We choose $n$ to range from 2000 to 10000 with a step size of 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>STD</th>\n",
       "      <th>REPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>31.606961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>24.474477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>22.338308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>28.850188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6000</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>29.259919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7000</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>29.563491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>31.606961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9000</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>28.586392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>27.716976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n         p       STD      REPS \n",
       "0   2000  0.001000  0.000707  31.606961\n",
       "1   3000  0.001667  0.000745  24.474477\n",
       "2   4000  0.002000  0.000706  22.338308\n",
       "3   5000  0.001200  0.000490  28.850188\n",
       "4   6000  0.001167  0.000441  29.259919\n",
       "5   7000  0.001143  0.000404  29.563491\n",
       "6   8000  0.001000  0.000353  31.606961\n",
       "7   9000  0.001222  0.000368  28.586392\n",
       "8  10000  0.001300  0.000360  27.716976"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "nn = np.arange(2000,10001,1000)\n",
    "resmat = np.zeros((3,len(nn)))\n",
    "for count, n in enumerate(nn):\n",
    "    resmat[:,count] = id_mc(n)\n",
    "d = {'n' : nn,\n",
    "     r'p' : resmat[0,:], \n",
    "     r'STD' : resmat[1,:],\n",
    "     r'REPS ' : resmat[2,:]}    \n",
    "df_id = pd.DataFrame(d)\n",
    "display(df_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Entropy (CE) Method for Rare Event Simulation\n",
    "\n",
    "Suppose after a good biasing distribution is constructed out of CE, the importance-sampling-based estimator of $p$ has the form of\n",
    "$$\n",
    "\\hat{p}_n^{IS} = \\dfrac{1}{n} \\sum_{i=1}^n \\mathbb{1}\\{u(0.6,w_i) > 40\\} \\cdot W(w_i)\n",
    "$$\n",
    "where $W(w_i)$ are the weights. Then the standard deviation has the form of \n",
    "$$\n",
    "\\hat{\\sigma}_n^{IS} = \\dfrac{\\left(\\sum_{i=1}^n \\hat{p}_n^{IS}(1-\\hat{p}_n^{IS}) \\cdot W(w_i)^2\\right)^{1/2}}{n}\n",
    "$$\n",
    "and thus, the REPS takes the form of \n",
    "$$\n",
    "\\dfrac{\\sqrt{n}\\hat{\\sigma}_n}{\\hat{p}_n} = \\sqrt{\\dfrac{(1-\\hat{p}_n^{IS})}{n\\hat{p}_n^{IS}}\\cdot \\sum_{i=1}^n W(w_i)^2}.\n",
    "$$\n",
    "\n",
    "### Implementation of CE\n",
    "The implementation of CE is presented below. The core method is `ce_train`. We provide implementations for 3 classes of biasing distributions\n",
    "1. multivariate Gaussian with diagonal covariance matrix,\n",
    "2. multivariate Gaussian with general SPD covariance matrix, and\n",
    "3. other parameterized family of distributions,\n",
    "\n",
    "and provide testing results for the first 2 cases. \n",
    "\n",
    "Note that for the first two cases, we have closed form update formula for the mean and the covariance matrix as presented in [the paper](https://mediatum.ub.tum.de/doc/1456133/document.pdf). The update rule is implemented in `normal_update`. Note that the formula will always give out a dense covariance matrix. Therefore, to ensure uncorrelation in case 1, we manually truncate the matrix to be diagonal. \n",
    "\n",
    "For the third case, we call the optimizer `scipt.optimize.minimize` to do the inner optimization for us. The loss function is implemented in `ce_loss`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize \n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "def init(option):\n",
    "    if option=='normal uncorr':\n",
    "        # mu = np.asarray([0.5, -1, -0.5, -5, -1])\n",
    "        mu = -np.ones(5)\n",
    "        s = np.eye(5).reshape(-1)\n",
    "        theta = np.hstack((mu,s))\n",
    "        return theta\n",
    "    elif option=='normal corr':\n",
    "        mu = -np.ones(5)\n",
    "        s = np.eye(5).reshape(-1)\n",
    "        theta = np.hstack((mu,s))\n",
    "        return theta\n",
    "    else:\n",
    "        ValueError(\"{option} is not implemented!\")\n",
    "\n",
    "def sampler(theta, option='normal uncorr'):\n",
    "    if option.split()[0]=='normal':\n",
    "        mu = theta[:5]\n",
    "        s = theta[5:]\n",
    "        S = s.reshape(5,5)\n",
    "        return mvn(mean=mu, cov=S)\n",
    "    else:\n",
    "        ValueError(\"{option} is not implemented!\")\n",
    "\n",
    "def sample_g(theta, n, option):\n",
    "    var = sampler(theta, option)\n",
    "    x = var.rvs(size=n)\n",
    "    gx = var.pdf(x)\n",
    "    return x, gx\n",
    "\n",
    "def ce_loss(theta, x, px, gx_j, option):\n",
    "    \"\"\" \n",
    "    gx_j : density for biasing distribution\n",
    "    \"\"\"\n",
    "    u06 = sde_mc(n, X=x) # \n",
    "    u06 = np.asarray(u06)\n",
    "    hx = np.where(u06 > 40, 1, 0)\n",
    "\n",
    "    var = sampler(theta, option)\n",
    "    gx = var.pdf(x) # density for current theta\n",
    "\n",
    "    hpx = px * hx # unnormalized density of h(x)p(x)\n",
    "    wx = hpx / gx_j # IS weight\n",
    "    \n",
    "    log_gx = np.log(gx)\n",
    "    J = np.mean(wx*log_gx)\n",
    "    return -J\n",
    "\n",
    "def normal_update(theta, n, p, option):\n",
    "    \"\"\" \n",
    "    closed form update of the normal density\n",
    "    \"\"\"\n",
    "    x, gx = sample_g(theta, n, option)\n",
    "    u06 = sde_mc(n, X=x)\n",
    "    u06 = np.asarray(u06)\n",
    "    hx = np.where(u06 > 40, 1, 0)\n",
    "    px = p(x) # original density\n",
    "    wx = px / gx # original density / biasing density\n",
    "    hwx = hx * wx \n",
    "    hwx = hwx / hwx.sum() # normalize\n",
    "    hwx = hwx.reshape(n,1) # reshape to broadcast\n",
    "    mu = (x*hwx).sum(axis=0)\n",
    "    assert mu.shape == (5,)\n",
    "\n",
    "    mu_vec = mu.reshape(-1,1)\n",
    "    S = np.zeros((5,5))\n",
    "    for i in range(n):\n",
    "        xi = x[i,:].reshape(-1,1)\n",
    "        S += hwx.squeeze()[i] * (xi-mu_vec)@(xi-mu_vec).T\n",
    "    \n",
    "    if option.split()[1] == 'uncorr':\n",
    "        # if uncorrelated, truncate\n",
    "        S = np.diag(np.diagonal(S))\n",
    "        \n",
    "    return mu,S \n",
    "\n",
    "def ce_train(p, n, option='normal uncorr', maxits=1):\n",
    "    \"\"\" \n",
    "    Cross Entropy method\n",
    "    Goal: find a good biasing distribution for doing importance sampling\n",
    "          a good biasing distribution should be similar to  |h(x)|p(x)\n",
    "\n",
    "    p : input distribution\n",
    "    \"\"\"\n",
    "    theta_j = init(option)\n",
    "\n",
    "    if option.split()[0]=='normal':\n",
    "        for _ in range(maxits): \n",
    "            mu, S = normal_update(theta_j, n, p, option)\n",
    "            theta_j = np.hstack((mu, S.reshape(-1)))\n",
    "        return theta_j\n",
    "    \n",
    "    # if biasing class is not normal, no closed form and use optimizer\n",
    "    for _ in range(maxits):\n",
    "        x, gx = sample_g(theta_j, n, option) # draw n samples from g_theta_i (n,5) (Y,F\n",
    "        px = p(x) # (n,) known density of original distribution of x\n",
    "        loss = lambda theta : ce_loss(theta, x, px, gx, option)\n",
    "        res = minimize(loss, theta_j)\n",
    "        theta_j = res.x\n",
    "    \n",
    "    return theta_j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide several numerical experiments to demonstrate the algorithm. Below we present the result for using uncorrelated multivariate normal distribution as the biasing distribution. To ensure the algorithm does not encounter overflow at the beginning, we need to have either a good initialization, or a large enough sample size (or both). Here, we let the sample size run from 2000 to 5000 with a step size of 1000. We select a simple initialization so that the initial mean vector is full of -1 and the covariance matrix is the identity matrix. We run the method for 10 iterations to obtain the parameter that defines the biasing distribution. With that parameter, we compute the importance-sampling-based estimate of $p$, its standard deviation, and the relative error per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:32, 23.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>STD</th>\n",
       "      <th>REPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>16.438551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>3.870158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>16.446418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>7.134117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n         p       STD      REPS \n",
       "0  2000  0.001117  0.000410  16.438551\n",
       "1  3000  0.001041  0.000074   3.870158\n",
       "2  4000  0.001090  0.000283  16.446418\n",
       "3  5000  0.001112  0.000112   7.134117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "\n",
    "np.random.seed(0)\n",
    "nn = [2000, 3000, 4000, 5000]\n",
    "\n",
    "# construct original distribution\n",
    "mu = np.asarray([-1,-1,-1,-1,-2])\n",
    "s = np.asarray([1,1,1,1,0.5])\n",
    "S = np.diag(s)\n",
    "var = mvn(mean=mu, cov=S)\n",
    "p = lambda x : var.pdf(x)\n",
    "\n",
    "# record result\n",
    "resmat = np.zeros((3,len(nn)))\n",
    "\n",
    "# ce config\n",
    "option = 'normal uncorr'\n",
    "maxits = 10\n",
    "for count, n in tqdm(enumerate(nn)):\n",
    "    theta = ce_train(p,n,option,maxits)\n",
    "    x,gx = sample_g(theta, n, option)\n",
    "    wx = p(x) / gx  # importance sampling weight\n",
    "    resmat[:,count] = id_mc(n, X=x, IS=True, wx=wx)\n",
    "\n",
    "d = {'n' : nn,\n",
    "     r'p' : resmat[0,:], \n",
    "     r'STD' : resmat[1,:],\n",
    "     r'REPS ' : resmat[2,:]}    \n",
    "df_ce = pd.DataFrame(d)\n",
    "display(df_ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result above is not the best we can get. We have tried different configurations for the method (initialization, number of iterations, etc.) and have obtained better result. But from the result above, we can already see that the REPS is decreased by a substantial amount compared to the vanilla Monte Carlo estimation.\n",
    "\n",
    "Below we present the result for using correlated multivariate normal distribution as the biasing distribution. Everything else stays the same as the previous experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:51, 12.89s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>STD</th>\n",
       "      <th>REPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1.862702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>2.535822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.088884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>5.118815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n         p       STD     REPS \n",
       "0  2000  0.001049  0.000044  1.862702\n",
       "1  3000  0.001023  0.000047  2.535822\n",
       "2  4000  0.001117  0.000019  1.088884\n",
       "3  5000  0.001099  0.000080  5.118815"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resmat = np.zeros((3,len(nn)))\n",
    "\n",
    "# ce config\n",
    "option = 'normal corr'\n",
    "maxits = 5\n",
    "for count, n in tqdm(enumerate(nn)):\n",
    "    theta = ce_train(p,n,option,maxits)\n",
    "    x,gx = sample_g(theta, n, option)\n",
    "    wx = p(x) / gx  # importance sampling weight\n",
    "    resmat[:,count] = id_mc(n, X=x, IS=True, wx=wx)\n",
    "\n",
    "d = {'n' : nn,\n",
    "     r'p' : resmat[0,:], \n",
    "     r'STD' : resmat[1,:],\n",
    "     r'REPS ' : resmat[2,:]}    \n",
    "df_ce_corr = pd.DataFrame(d)\n",
    "display(df_ce_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With correlated Gaussian, we again see a substantial performance gain, in terms of the REPS quantity, compared to before. Interestingly, the REPS in this case is even a lot smaller than the uncorrelated Gaussian case. Intuitively, this makes sense because we are taking more information into account and allowing more complexity in the family of biasing distributions we are considering. However, there are many more factors to take into account before we draw any conclusion about this, such as initialization, randomness in the data, number of optimization iterations, etc. We leave the discussion here as it is beyond the scope of the assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
